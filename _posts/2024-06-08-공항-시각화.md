---
title: 공항 실시간 운항 정보 및 주차, 날씨 정보 시각화 후기
tags: Project
---

# 프로젝트 소개

이 프로젝트는 항공기 운행 데이터, 공항 주차장 데이터, 날씨 데이터를 통합하여 이들 간의 상관관계를 분석하고 시각화하는 것을 목표로 합니다. 항공기 운항 지연의 원인 파악, 주차장 이용 패턴 분석, 날씨 조건의 영향을 종합적으로 이해함으로써 공항 운영의 효율성을 향상시키고자 합니다. 데이터를 수집, 전처리, 분석하고 시각화를 통해 인사이트를 도출하여, 항공기 운항 계획, 주차장 운영 방안, 기상 대응 전략 등에 대한 개선 방안을 제시합니다.

 이를 통해 공항 관리자는 보다 효과적인 운영 전략을 수립하고 항공기 지연을 최소화하며, 주차장 이용 편리성을 높이고 기상 조건에 대한 대응력을 강화할 수 있습니다.

- [GitHub 링크](https://github.com/pdc-3-project/gce-airflow)
- [Notion 링크](https://project-public.notion.site/3-_-6c55300cf340403e89e6be05ca0d903a?pvs=74)

## 참여 역할
- 공항별 실시간 주차장 정보(시간별 주차장별 혼잡도) DAG 작성
- 공항별 실시간 주차장 정보(시간별 주차장별 혼잡도) ETL 작성
- 실시간 주차 정보 관련 대시보드 시각화

---

## 첫 번째 이슈: 데이터 파이프라인에서의 시차 문제

### 문제의 배경
- **시차 처리 문제**: Airflow DAG의 `execution_date`를 처리할 때, UTC와 KST 간의 시차를 정확히 반영하는 데 어려움이 있었음.
- **XCom을 통한 데이터 전송**: `execution_date`를 XCom을 통해 전달하는 과정에서 시차로 인한 데이터 불일치가 발생할 수 있음.

**해결하지 않을 시**: 데이터의 정확성과 일관성을 보장할 수 없어, 최종 데이터 분석 결과에 오류가 발생할 수 있음.

### 시도한 해결 방법
- **`convert_to_kst` 함수 도입**: `execution_date`를 KST로 변환하기 위한 함수를 도입하였으나, XCom을 통해 전달할 때 여전히 시차 문제 발생.

---

### 첫 번째 이슈 해결 과정

#### 최종 해결 방법: `set_kst_execution_date` 및 `get_kst_execution_date_path` 함수 개선

##### 해결 방법:
- **`set_kst_execution_date` 개선**: `execution_date`를 KST로 변환하여 XCom에 저장하는 방식을 채택.
- **`get_kst_execution_date_path` 개선**: XCom에서 KST 변환된 날짜를 받아 적절한 경로를 형성하도록 개선.

##### 구체적인 코드 예제:

```python
def convert_to_kst(execution_date):
    execution_date_utc = execution_date.replace(tzinfo=pytz.UTC)
    execution_date_kst = execution_date_utc.astimezone(pytz.timezone('Asia/Seoul'))
    return execution_date_kst.strftime('%Y-%m-%d %H:%M:%S')

def set_kst_execution_date(**kwargs):
    execution_date = kwargs['execution_date']
    execution_date_kst = convert_to_kst(execution_date)
    ti = kwargs['ti']
    ti.xcom_push(key='execution_date_kst', value=execution_date_kst)

def get_kst_execution_date_path(**kwargs):
    ti = kwargs['ti']
    execution_date_kst = ti.xcom_pull(task_ids='set_kst_execution_date', key='execution_date_kst')
    execution_date_kst_dt = datetime.strptime(execution_date_kst, '%Y-%m-%d %H:%M:%S')
    formatted_day = execution_date_kst_dt.strftime("%d")
    formatted_timestamp = execution_date_kst_dt.strftime("%Y%m%d%H%M")
    return f'source/source_parkinglot/CJU_parking_data/2024/06/{formatted_day}/CJU_parking_data_{formatted_timestamp}.csv'

```

#### 해결 후 결과
- **정확한 시차 반영**: `execution_date`를 정확히 KST로 변환하여 데이터 경로와 저장 시차를 정확히 반영.
- **데이터 일관성 향상**: 시차 문제로 인한 데이터 불일치가 해결되어, 데이터 분석의 정확성이 향상되었습니다.

---

### 배운 점 및 교훈

이 과정을 통해 배운 것은 다음과 같습니다:
- **시차 처리의 중요성**: 글로벌 데이터 처리에서 시차를 정확히 처리하는 것이 얼마나 중요한지 깨달았습니다.
- **XCom을 활용한 데이터 전송**: XCom을 통해 데이터를 전달할 때, 시간 정보와 같은 중요 데이터를 신중하게 처리해야 한다는 교훈을 얻었습니다.

#### 추가 개선 가능성
- 시차를 처리하는 방법을 더욱 정교하게 다듬어, 다양한 시간대에서의 데이터 일관성을 유지할 수 있도록 추가적인 검토가 필요할 수 있습니다.

---

### 결론

시차 문제를 해결하는 과정에서 많은 교훈을 얻었으며, 시간대 변환의 중요성을 다시 한 번 인식하게 되었습니다. 이 글이 비슷한 문제를 겪는 분들에게 도움이 되길 바랍니다.

### 추가 자료
- [Pytz 관련 정리 페이지](https://edykim.com/ko/post/pytz-python-library-for-world-time-zone-definition/)
- [Airflow XCom Documentation](https://airflow.apache.org/docs/apache-airflow/stable/concepts/xcoms.html)

---

### Q&A

**Q: Airflow에서 `execution_date`를 KST로 변환하는 이유는 무엇인가요?**

**A:** Airflow는 기본적으로 UTC 시간대를 사용합니다. 그러나 한국 표준시(KST)로 데이터를 처리하거나 결과를 제공해야 하는 경우, `execution_date`를 KST로 변환하여 로컬 시간대와 일관된 데이터를 처리할 필요가 있습니다. 이를 통해 데이터의 정확성과 일관성을 보장할 수 있습니다.

**Q: XCom을 사용할 때 시차 문제를 어떻게 해결하였나요?**

**A:** XCom을 사용할 때 시차 문제를 해결하기 위해 `execution_date`를 KST로 변환하여 저장하고, 변환된 값을 다시 불러와서 사용하는 방법을 채택했습니다. 이를 통해 데이터 경로 및 시간 관련 정보를 정확히 반영할 수 있었습니다.

---

## 두 번째 이슈: GCS와 BigQuery 간의 데이터 로딩 문제

### 문제의 배경
- **데이터 형식 문제**: GCS에서 Parquet 형식의 데이터를 BigQuery로 로드할 때, 데이터 스키마와 형식 불일치 문제 발생.
- **스키마 매핑 문제**: GCS에서 업로드된 데이터의 스키마와 BigQuery 테이블의 스키마 간의 차이로 인해 데이터 로딩 오류가 발생하였음.

**해결하지 않을 시**: 데이터 로딩 오류로 인해 분석 데이터가 손실될 수 있으며, 분석 결과의 신뢰성이 떨어질 수 있음.

### 시도한 해결 방법
- **스키마 재설정**: BigQuery 테이블의 스키마를 GCS 데이터와 맞추기 위해 재설정하려 했으나, 이 과정에서 복잡한 데이터 구조로 인해 문제 해결이 어려움.

---

### 두 번째 이슈 해결 과정

#### 최종 해결 방법: `GCSToBigQueryOperator` 설정 및 스키마 조정

##### 해결 방법:
- **`GCSToBigQueryOperator` 활용**: GCS에서 Parquet 형식의 데이터를 BigQuery로 로드하기 위해 `GCSToBigQueryOperator`를 설정.
- **스키마 명시**: 데이터의 정확한 스키마를 명시하여 BigQuery와 GCS 간의 데이터 형식 불일치를 해결.

##### 구체적인 코드 예제:

```python
load_to_bigquery_task = GCSToBigQueryOperator(
    task_id=f'load_{airport}_to_bigquery',
    bucket='pdc3project-stage-layer-bucket',
    source_objects=source_object,
    destination_project_dataset_table=f'pdc3project.raw_data.parking_data_{airport}',
    source_format='PARQUET',
    write_disposition='WRITE_APPEND',
    schema_fields=[
        {'name': 'airportKor', 'type': 'STRING', 'mode': 'NULLABLE'},
        {'name': 'parkingAirportCodeName', 'type': 'STRING', 'mode': 'NULLABLE'},
        {'name': 'parkingCongestion', 'type': 'STRING', 'mode': 'NULLABLE'},
        {'name': 'parkingCongestionDegree', 'type':'INTEGER', 'mode': 'NULLABLE'},
        {'name': 'parkingOccupiedSpace', 'type':'INTEGER', 'mode': 'NULLABLE'},
        {'name': 'parkingTotalSpace', 'type': 'INTEGER', 'mode': 'NULLABLE'},
        {'name': 'datetm', 'type': 'INTEGER', 'mode': 'NULLABLE'},
    ],
    gcp_conn_id='google_cloud_bigquery',
    dag=dag,
)

```

#### 해결 후 결과
- **정확한 데이터 로딩**: Parquet 형식의 데이터를 BigQuery로 정확히 로드할 수 있게 되었으며, 데이터 분석의 신뢰성을 확보했습니다.
- **스키마 일치**: BigQuery와 GCS 간의 데이터 스키마 일치 문제를 해결하여 데이터 처리 과정의 안정성을 향상시켰습니다.

---

### 배운 점 및 교훈

이 과정을 통해 배운 것은 다음과 같습니다:
- **데이터 스키마 관리**: 데이터 로딩 과정에서 스키마 관리의 중요성을 인식했습니다. 데이터의 정확한 형식과 구조를 명시하는 것이 데이터 처리의 핵심임을 깨달았습니다.
- **운영 최적화**: 데이터 파이프라인의 각 단계에서의 세심한 설정과 최적화가 데이터 분석의 정확성과 신뢰성에 직접적인 영향을 미친다는 교훈을 얻었습니다.

#### 추가 개선 가능성
- 데이터 로딩 과정에서의 오류를 사전에 예방하기 위해 스키마 검증 및 데이터 형식 검토를 더욱 철저히 할 필요가 있습니다.

---

### 결론

GCS와 BigQuery 간의 데이터 로딩 문제를 해결하는 과정에서 많은 교훈을 얻었으며, 데이터 스키마 관리의 중요성을 다시 한 번 인식하게 되었습니다. 이 글이 비슷한 문제를 겪는 분들에게 도움이 되길 바랍니다.

### 추가 자료
- [Google Cloud Storage to BigQuery Documentation](https://cloud.google.com/bigquery/external-data-cloud-storage?hl=ko)
- [BigQuery Schema Documentation](https://cloud.google.com/bigquery/docs/schemas?hl=ko)

---

### Q&A

**Q: GCS에서 BigQuery로 데이터 로딩 시 스키마 문제를 어떻게 해결했나요?**

**A:** GCS에서 BigQuery로 데이터 로딩 시 발생하는 스키마 문제를 해결하기 위해 `GCSToBigQueryOperator`를 사용하였고, BigQuery 테이블의 스키마를 GCS 데이터의 스키마에 맞추어 명시적으로 설정하였습니다. 이를 통해 데이터 형식 불일치 문제를 해결하였습니다.

**Q: Parquet 형식의 데이터를 BigQuery로 로드할 때 주의해야 할 점은 무엇인가요?**

**A:** Parquet 형식의 데이터를 BigQuery로 로드할 때는 데이터 스키마의 정확한 매핑이 필요합니다. Parquet 파일의 스키마와 BigQuery 테이블의 스키마가 일치하지 않으면 로딩 오류가 발생할 수 있습니다. 따라서, 데이터의 스키마를 명확히 정의하고, 형식 검증을 통해 데이터 로딩 오류를 예방하는 것이 중요합니다.

---
